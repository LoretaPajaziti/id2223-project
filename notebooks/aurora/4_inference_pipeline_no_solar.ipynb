{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5e6dd8b",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: /Users/appbites/Desktop/id2223-project\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('aurora',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77b405-f92d-40c2-941c-bb18cbe89657",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab2efec4",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import hopsworks\n",
    "import json\n",
    "from mlfs.aurora import util\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ce0e73d-7fae-41e8-8305-06995fa11d97",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "KP_FG = dict(name=\"geomagnetic_daily_final\", version=1)\n",
    "WEATHER_FG = dict(name=\"sweden_weather_daily_final\", version=1)\n",
    "\n",
    "AURORA_FV = dict(name=\"aurora_fv_final\", version=1)\n",
    "\n",
    "PRED_FG = (\"aurora_predictions\", 1)\n",
    "\n",
    "MODEL_NAME = \"aurora_xgboost\"   # el prefijo que usas en training: f\"{MODEL_NAME}_h{h}\"\n",
    "MAX_HORIZON = 5               # o el que uses\n",
    "AP_THRESHOLD = 15             # tu umbral del evento\n",
    "\n",
    "DATA_PATH = \"../../data\"\n",
    "RUN_DATE = datetime.datetime.utcnow().date()- datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0d132-9f5b-44be-aa68-c6814a70937c",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Hopsworks Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9262f1a",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:18:47,633 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2026-01-05 23:18:47,670 INFO: Initializing external client\n",
      "2026-01-05 23:18:47,671 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-05 23:18:48,357 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:18:49,386 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1289364\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store()    # Feature Store\n",
    "mr = project.get_model_registry()  # Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc4f14-7b4b-4027-93a0-be0fb40b075a",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## 1. Fetch the Inference Data and Add it to the Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98252c82-89f7-4d19-9eca-54adc3ed4d3f",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def fetch_kp():\n",
    "    # Obtain data\n",
    "    df = util.get_latest_complete_kp_from_nowcast()\n",
    "\n",
    "    # Insert into feature store\n",
    "    kp_fg = fs.get_feature_group(**KP_FG)\n",
    "    kp_fg.insert(df, wait=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa6b183b-39d8-4e88-bcac-7cf6692bd1bc",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def fetch_weather(run_date):\n",
    "\n",
    "    LATITUDE = 62.0\n",
    "    LONGITUDE = 15.0\n",
    "\n",
    "    run_date = pd.to_datetime(run_date).date()\n",
    "    date_str = run_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df = util.get_historical_weather_sweden(\n",
    "        start_date=run_date - pd.Timedelta(days=7),\n",
    "        end_date=date_str,\n",
    "        latitude=LATITUDE,\n",
    "        longitude=LONGITUDE,\n",
    "    )\n",
    "\n",
    "    weather_fg = fs.get_feature_group(**WEATHER_FG)\n",
    "    weather_fg.insert(df, wait=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10c5e4d4-842d-4b3f-9c36-b5209e113532",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def build_features(raw: dict) -> pd.DataFrame:\n",
    "    df = build_feature_dataframe(\n",
    "        kp=raw[\"kp\"],\n",
    "        weather=raw[\"weather\"],\n",
    "    )\n",
    "\n",
    "    # último timestamp disponible\n",
    "    df = df.sort_index().iloc[-1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aef6e7bc-6f4d-4b8d-a0f9-e028872468c0",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name: str):\n",
    "    mr = project.get_model_registry()\n",
    "    model = mr.get_model(\n",
    "        name=model_name,\n",
    "        alias=\"champion\"\n",
    "    )\n",
    "    return model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e61f33-869b-49c0-80d8-271dcb7c5a82",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "### Steps of the main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0be7227-24af-4ef5-a3fa-ca71352e4795",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "def fetch_latest_raw_data():\n",
    "    # Fetch latest geomagnetic data (includes several recent days)\n",
    "    kp_df = fetch_kp()\n",
    "\n",
    "    # Normalize dates\n",
    "    kp_df[\"date\"] = pd.to_datetime(kp_df[\"date\"]).dt.normalize()\n",
    "\n",
    "    # Use the latest available date as \"today\"\n",
    "    date = kp_df[\"date\"].iloc[-1]\n",
    "\n",
    "    print(\"Last data from kp:\", date)\n",
    "\n",
    "    # Fetch weather for the same window (already returns several days)\n",
    "    weather_df = fetch_weather(date)\n",
    "\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"]).dt.normalize()\n",
    "\n",
    "    # --- Build 5-day context window ---\n",
    "    context = []\n",
    "\n",
    "    # Take last 5 days where both kp + weather exist\n",
    "    kp_recent = kp_df.tail(5).reset_index(drop=True)\n",
    "\n",
    "    for _, row in kp_recent.iterrows():\n",
    "        day = row[\"date\"]\n",
    "\n",
    "        # Match weather row for the same date\n",
    "        w_row = weather_df[weather_df[\"date\"] == day]\n",
    "        if w_row.empty:\n",
    "            continue\n",
    "\n",
    "        w_row = w_row.iloc[0]\n",
    "\n",
    "        context.append({\n",
    "            \"date\": str(day.date()),\n",
    "            \"geomagnetic\": {\n",
    "                \"ap\": float(row[\"ap\"]),\n",
    "                \"kp_max\": float(\n",
    "                    max(row[f\"kp{i}\"] for i in range(1, 9))\n",
    "                )\n",
    "            },\n",
    "            \"weather\": {\n",
    "                \"cloud_cover\": float(w_row[\"cloud_cover_mean\"]),\n",
    "                \"precipitation\": float(w_row[\"precipitation_sum\"])\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # --- Persist context ---\n",
    "    out_dir = Path(\"../../docs/aurora/assets\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(out_dir / \"context.json\", \"w\") as f:\n",
    "        json.dump(context, f, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(context)} days of context to context.json\")\n",
    "\n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da46908b-6023-4c5e-bbc6-a832d39ad947",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "def obtain_data_fv(date):\n",
    "\n",
    "    date = pd.to_datetime(date, utc=True).normalize()\n",
    "    \n",
    "    fv = fs.get_feature_view(**AURORA_FV)\n",
    "\n",
    "    X = fv.get_batch_data(\n",
    "        start_time=date - pd.Timedelta(days=7),\n",
    "        end_time=date\n",
    "    )\n",
    "\n",
    "    print(X.columns)\n",
    "\n",
    "    print(f\"Number of days retrieved from FV: {len(X)}\")\n",
    "\n",
    "    if len(X) < 7:\n",
    "        raise RuntimeError(f\"Expected 7 row from Feature View, got {len(X)}\")\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e502c486-0500-4e9c-b190-9471e5fb3e68",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "def run_models(X: pd.DataFrame, date) -> pd.DataFrame:\n",
    "    mr = project.get_model_registry()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for h in range(1, MAX_HORIZON + 1):\n",
    "        print(f\"Running {MODEL_NAME}_h{h}\")\n",
    "        model_name = f\"{MODEL_NAME}_h{h}\"\n",
    "\n",
    "        model = mr.get_model(\n",
    "            name=model_name,\n",
    "            version = 1\n",
    "        )\n",
    "        \n",
    "        fv = model.get_feature_view()\n",
    "\n",
    "        model_dir = model.download()\n",
    "\n",
    "        clf = joblib.load(f\"{model_dir}/model.pkl\")\n",
    "\n",
    "        y_proba = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "        result = {\n",
    "            \"timestamp\": date + pd.Timedelta(days=h),\n",
    "            \"horizon_days\": h,\n",
    "            \"probability\": float(y_proba[0]),\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    # out_dir = Path(DATA_PATH)\n",
    "    # out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # pd.DataFrame(results).to_json(\n",
    "    #     out_dir / \"predictions.json\",\n",
    "    #     orient=\"records\",\n",
    "    #     indent=2\n",
    "    # )\n",
    "\n",
    "    out_dir = Path(root_dir) / \"docs\" / \"aurora\" / \"assets\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame(results).to_json(\n",
    "        out_dir / \"predictions.json\",\n",
    "        orient=\"records\",\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Saved {len(results)} predictions to {out_dir / 'predictions.json'}\")\n",
    "\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a79436df-cc4c-400a-9ca6-c47be1c9b6be",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 4\n",
    "def save_predictions(df: pd.DataFrame):\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"aurora_predictions\",\n",
    "        version=1,\n",
    "        primary_key=[\"timestamp\", \"horizon_days\"],\n",
    "        description=\"Daily batch aurora predictions\",\n",
    "    )\n",
    "\n",
    "    fg.insert(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d623fe-ff43-476b-887b-20ef6ca666de",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a6b3cbc",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:18:50,933 WARNING: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "2026-01-05 23:18:51,723 INFO: \t17 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1289364/fs/1278019/fg/1893812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: geomagnetic_daily_final_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1289364/jobs/named/geomagnetic_daily_final_1_offline_fg_materialization/executions\n",
      "2026-01-05 23:19:12,676 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2026-01-05 23:19:15,925 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-05 23:20:59,928 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-05 23:21:00,114 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-05 23:21:15,776 INFO: Execution finished successfully.\n",
      "Last data from kp: 2026-01-05 00:00:00\n",
      "2026-01-05 23:21:16,469 INFO: \t3 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1289364/fs/1278019/fg/1893813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 8/8 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sweden_weather_daily_final_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1289364/jobs/named/sweden_weather_daily_final_1_offline_fg_materialization/executions\n",
      "2026-01-05 23:21:34,353 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-05 23:21:40,847 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-05 23:23:18,159 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: SUCCEEDED\n",
      "2026-01-05 23:23:18,331 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-05 23:23:30,577 INFO: Execution finished successfully.\n",
      "Saved 5 days of context to context.json\n",
      "Date used one the fetch data raw 2026-01-05 00:00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.46s) \n",
      "Index(['date', 'kp1', 'kp2', 'kp3', 'kp4', 'kp5', 'kp6', 'kp7', 'kp8', 'ap1',\n",
      "       'ap2', 'ap3', 'ap4', 'ap5', 'ap6', 'ap7', 'ap8', 'cloud_cover_mean',\n",
      "       'precipitation_sum', 'sunshine_duration'],\n",
      "      dtype='object')\n",
      "Number of days retrieved from FV: 7\n",
      "Running aurora_xgboost_h1\n",
      "2026-01-05 23:23:43,470 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508571f75e33449286215e19b716e0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/499481 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b1d6c547104b529ad5aaf6a8cea9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/450484 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2384824f710340ab89fcf97fd514f633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/31032 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42495424dfce40e6b12477bc2bb3b81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/12060 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9647a48c5584799a55a6875dd55a91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/32832 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h2t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 23:23:52,609 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1b428bda1f45f7806d25a7bfae2abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/500501 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babf8c07c1684110a5489c2fac8fc72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/455992 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c79a22c85249018f722dbf593ca4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/31181 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e37434101fd4364bba7086677aa39ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/12054 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc60a17d151432bbae3868036eda9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/35070 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h3t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 23:24:01,971 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3ee1c5c10b4ad68646b093ad436fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/494245 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e126b4694a4458a21d49443e7c99c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/455652 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1556ee821c4f299bfd94b68793496c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/30116 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e70731bec14c528a8c9d652978d6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/11987 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23111c2cacb94eb490614dfbfed6fd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/35190 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h4t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 23:24:12,044 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598c8343827840aebbd4f12bea8b8508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/491593 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ce4a5dfd0d49feb466476848f53885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/456672 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2230c4b7ec433186799c227e68aa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/32010 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703d446fa8dd48b1bc377241c54be46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/11859 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c45a4c633184c75a727bb91b0d24e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/34964 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h5t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 23:24:21,763 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492992c25b284edda9bc2be153007146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/494721 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b437f99b89402b88b33049d361c19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/462656 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272b5ecd370e4761bedd141fc171b827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/31184 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e826479f4cb41f6b533d5bbffb6e6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/11691 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd7dd04029a4171b5185ec636e7e438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/35011 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 predictions to /Users/appbites/Desktop/id2223-project/docs/aurora/assets/predictions.json\n",
      "                  timestamp  horizon_days  probability\n",
      "0 2026-01-05 00:00:00+00:00             1     0.450832\n",
      "1 2026-01-06 00:00:00+00:00             2     0.511205\n",
      "2 2026-01-07 00:00:00+00:00             3     0.497482\n",
      "3 2026-01-08 00:00:00+00:00             4     0.482068\n",
      "4 2026-01-09 00:00:00+00:00             5     0.540067\n"
     ]
    }
   ],
   "source": [
    "def run_daily_inference():\n",
    "    date = fetch_latest_raw_data()\n",
    "\n",
    "    print(\"Date used one the fetch data raw\", date)\n",
    "    X = obtain_data_fv(date)\n",
    "\n",
    "    X_engi = util.geomagnetic_feature_engineering(X)\n",
    "    \n",
    "    X_engi = X_engi.sort_values(\"date\").tail(1).reset_index(drop=True)\n",
    "    \n",
    "    date = X_engi.loc[0, \"date\"]\n",
    "\n",
    "    X_engi.drop(columns=['date'], inplace=True)\n",
    "    \n",
    "    predictions = run_models(X_engi, date)\n",
    "\n",
    "    print(predictions)\n",
    "    #save_predictions(predictions)\n",
    "\n",
    "\n",
    "run_daily_inference()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
