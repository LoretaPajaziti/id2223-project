{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5e6dd8b",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: /Users/appbites/Desktop/id2223-project\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('aurora',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77b405-f92d-40c2-941c-bb18cbe89657",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab2efec4",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import hopsworks\n",
    "import json\n",
    "from mlfs.aurora import util\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce0e73d-7fae-41e8-8305-06995fa11d97",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "KP_FG = dict(name=\"geomagnetic_daily_final\", version=1)\n",
    "WEATHER_FG = dict(name=\"sweden_weather_daily_final\", version=1)\n",
    "\n",
    "AURORA_FV = dict(name=\"aurora_fv_final\", version=1)\n",
    "\n",
    "PRED_FG = (\"aurora_predictions\", 1)\n",
    "\n",
    "MODEL_NAME = \"aurora_xgboost\"   # el prefijo que usas en training: f\"{MODEL_NAME}_h{h}\"\n",
    "MAX_HORIZON = 5               # o el que uses\n",
    "AP_THRESHOLD = 15             # tu umbral del evento\n",
    "\n",
    "DATA_PATH = \"../../data\"\n",
    "RUN_DATE = datetime.datetime.utcnow().date()- datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0d132-9f5b-44be-aa68-c6814a70937c",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Hopsworks Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9262f1a",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 22:51:26,345 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2026-01-05 22:51:26,351 INFO: Initializing external client\n",
      "2026-01-05 22:51:26,351 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-05 22:51:27,022 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 22:51:28,186 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1289364\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store()    # Feature Store\n",
    "mr = project.get_model_registry()  # Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc4f14-7b4b-4027-93a0-be0fb40b075a",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## 1. Fetch the Inference Data and Add it to the Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98252c82-89f7-4d19-9eca-54adc3ed4d3f",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def fetch_kp():\n",
    "    # Obtain data\n",
    "    df = util.get_latest_complete_kp_from_nowcast()\n",
    "\n",
    "    # Insert into feature store\n",
    "    kp_fg = fs.get_feature_group(**KP_FG)\n",
    "    kp_fg.insert(df, wait=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa6b183b-39d8-4e88-bcac-7cf6692bd1bc",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def fetch_weather(run_date):\n",
    "\n",
    "    LATITUDE = 62.0\n",
    "    LONGITUDE = 15.0\n",
    "\n",
    "    run_date = pd.to_datetime(run_date).date()\n",
    "    date_str = run_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df = util.get_historical_weather_sweden(\n",
    "        start_date=run_date - pd.Timedelta(days=7),\n",
    "        end_date=date_str,\n",
    "        latitude=LATITUDE,\n",
    "        longitude=LONGITUDE,\n",
    "    )\n",
    "\n",
    "    weather_fg = fs.get_feature_group(**WEATHER_FG)\n",
    "    weather_fg.insert(df, wait=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10c5e4d4-842d-4b3f-9c36-b5209e113532",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def build_features(raw: dict) -> pd.DataFrame:\n",
    "    df = build_feature_dataframe(\n",
    "        kp=raw[\"kp\"],\n",
    "        weather=raw[\"weather\"],\n",
    "    )\n",
    "\n",
    "    # último timestamp disponible\n",
    "    df = df.sort_index().iloc[-1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aef6e7bc-6f4d-4b8d-a0f9-e028872468c0",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name: str):\n",
    "    mr = project.get_model_registry()\n",
    "    model = mr.get_model(\n",
    "        name=model_name,\n",
    "        alias=\"champion\"\n",
    "    )\n",
    "    return model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e61f33-869b-49c0-80d8-271dcb7c5a82",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "### Steps of the main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0be7227-24af-4ef5-a3fa-ca71352e4795",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "def fetch_latest_raw_data():\n",
    "    kp_df = fetch_kp()\n",
    "\n",
    "    date = pd.to_datetime(kp_df[\"date\"].iloc[-1]).normalize()\n",
    "\n",
    "    print(\"last data from kp: \", date)\n",
    "    \n",
    "    weather_df = fetch_weather(date)\n",
    "\n",
    "\n",
    "    latest_context = {\n",
    "        \"date\": str(date.date()),\n",
    "        \"geomagnetic\": {\n",
    "            \"ap\": float(kp_df[\"ap\"].iloc[-1]),\n",
    "            \"kp_max\": float(kp_df[[f\"kp{i}\" for i in range(1,9)]].iloc[-1].max())\n",
    "        },\n",
    "        \"weather\": {\n",
    "            \"cloud_cover\": float(weather_df[\"cloud_cover_mean\"].iloc[-1]),\n",
    "            \"precipitation\": float(weather_df[\"precipitation_sum\"].iloc[-1])\n",
    "        }\n",
    "    }\n",
    "\n",
    "    out_dir = Path(\"../../docs/aurora/assets\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(out_dir / \"context.json\", \"w\") as f:\n",
    "        json.dump(latest_context, f, indent=2)\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da46908b-6023-4c5e-bbc6-a832d39ad947",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "def obtain_data_fv(date):\n",
    "\n",
    "    date = pd.to_datetime(date, utc=True).normalize()\n",
    "    \n",
    "    fv = fs.get_feature_view(**AURORA_FV)\n",
    "\n",
    "    X = fv.get_batch_data(\n",
    "        start_time=date - pd.Timedelta(days=7),\n",
    "        end_time=date\n",
    "    )\n",
    "\n",
    "    print(X.columns)\n",
    "\n",
    "    print(f\"Number of days retrieved from FV: {len(X)}\")\n",
    "\n",
    "    if len(X) < 7:\n",
    "        raise RuntimeError(f\"Expected 7 row from Feature View, got {len(X)}\")\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e502c486-0500-4e9c-b190-9471e5fb3e68",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "def run_models(X: pd.DataFrame, date) -> pd.DataFrame:\n",
    "    mr = project.get_model_registry()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for h in range(1, MAX_HORIZON + 1):\n",
    "        print(f\"Running {MODEL_NAME}_h{h}\")\n",
    "        model_name = f\"{MODEL_NAME}_h{h}\"\n",
    "\n",
    "        model = mr.get_model(\n",
    "            name=model_name,\n",
    "            version = 1\n",
    "        )\n",
    "        \n",
    "        fv = model.get_feature_view()\n",
    "\n",
    "        model_dir = model.download()\n",
    "\n",
    "        clf = joblib.load(f\"{model_dir}/model.pkl\")\n",
    "\n",
    "        y_proba = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "        result = {\n",
    "            \"timestamp\": date + pd.Timedelta(days=h),\n",
    "            \"horizon_days\": h,\n",
    "            \"probability\": float(y_proba[0]),\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    # out_dir = Path(DATA_PATH)\n",
    "    # out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # pd.DataFrame(results).to_json(\n",
    "    #     out_dir / \"predictions.json\",\n",
    "    #     orient=\"records\",\n",
    "    #     indent=2\n",
    "    # )\n",
    "\n",
    "    out_dir = Path(root_dir) / \"docs\" / \"aurora\" / \"assets\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame(results).to_json(\n",
    "        out_dir / \"predictions.json\",\n",
    "        orient=\"records\",\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Saved {len(results)} predictions to {out_dir / 'predictions.json'}\")\n",
    "\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a79436df-cc4c-400a-9ca6-c47be1c9b6be",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# Step 4\n",
    "def save_predictions(df: pd.DataFrame):\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"aurora_predictions\",\n",
    "        version=1,\n",
    "        primary_key=[\"timestamp\", \"horizon_days\"],\n",
    "        description=\"Daily batch aurora predictions\",\n",
    "    )\n",
    "\n",
    "    fg.insert(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d623fe-ff43-476b-887b-20ef6ca666de",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a6b3cbc",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 22:51:29,816 WARNING: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "\n",
      "2026-01-05 22:51:30,567 INFO: \t17 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1289364/fs/1278019/fg/1893812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: geomagnetic_daily_final_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1289364/jobs/named/geomagnetic_daily_final_1_offline_fg_materialization/executions\n",
      "2026-01-05 22:51:51,322 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-05 22:51:57,780 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-05 22:53:50,875 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-05 22:53:51,049 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-05 22:53:59,745 INFO: Execution finished successfully.\n",
      "last data from kp:  2026-01-05 00:00:00\n",
      "2026-01-05 22:54:00,667 INFO: \t3 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1289364/fs/1278019/fg/1893813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 8/8 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sweden_weather_daily_final_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1289364/jobs/named/sweden_weather_daily_final_1_offline_fg_materialization/executions\n",
      "2026-01-05 22:54:19,484 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-05 22:54:22,711 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-05 22:56:09,467 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-05 22:56:09,654 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-05 22:56:21,828 INFO: Execution finished successfully.\n",
      "Date used one the fetch data raw 2026-01-05 00:00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.56s) \n",
      "Index(['date', 'kp1', 'kp2', 'kp3', 'kp4', 'kp5', 'kp6', 'kp7', 'kp8', 'ap1',\n",
      "       'ap2', 'ap3', 'ap4', 'ap5', 'ap6', 'ap7', 'ap8', 'cloud_cover_mean',\n",
      "       'precipitation_sum', 'sunshine_duration'],\n",
      "      dtype='object')\n",
      "Number of days retrieved from FV: 7\n",
      "Running aurora_xgboost_h1\n",
      "2026-01-05 22:56:34,845 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd715c1174da49bf89943172a9e94514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/499481 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bbc60854404fab91bd6139472a5c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/450484 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee799630352748288b834e0535a4eb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/31032 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c54a84eaf744d049ee10ef11c0bac98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/12060 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a37b2e9f784fbc88f7e23b688123fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/32832 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h2t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 22:56:44,551 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8be33409aa74ee18223c226af910870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/500501 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec8bd88b06241bfa0ba1762ca1f2382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/455992 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56e1736416e452fa36b9eb8721cb697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/31181 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76d918f83e24f4c8b911b0f228755bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/12054 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3f6cda2bc346e7a6d99cbe80afbb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/35070 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h3t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 22:56:54,988 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1be0eec9b2a4c75b36ca6f8ec891ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/494245 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc2363533c042b58bca351a69c174ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/455652 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6002cd6812b4fa88ec6efa8e884e89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/30116 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0797a116c783473d9d56252852b5fb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/11987 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116c112d39294132b4b4aacd05fec8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/35190 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h4t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 22:57:05,024 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897eee1819a943f28ed915a0ce701c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/491593 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cb2da1813d41b59555963dff239ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/456672 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636e8c6cdbb74079b163dcf097db711d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/32010 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c63bda60cd4f2ea78705bdd9124965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/11859 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaff226d53d4739bf606d4064d65495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/34964 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aurora_xgboost_h5t (1 dirs, 5 files)... DONE\n",
      "2026-01-05 22:57:15,140 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04bb44f4a7462fb3d39dd9728f839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/494721 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33096f3a56ed42bd8ef49168db340027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/462656 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f219c43fd56d48f9a36bf22e7ec9e9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/31184 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0273ad3a5d0468eaa31643ba68c692b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/11691 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7834e8b76ce440028449bec80b14256d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/35011 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 predictions to /Users/appbites/Desktop/id2223-project/docs/aurora/assets/predictions.json\n",
      "                  timestamp  horizon_days  probability\n",
      "0 2026-01-05 00:00:00+00:00             1     0.450832\n",
      "1 2026-01-06 00:00:00+00:00             2     0.511205\n",
      "2 2026-01-07 00:00:00+00:00             3     0.497482\n",
      "3 2026-01-08 00:00:00+00:00             4     0.482068\n",
      "4 2026-01-09 00:00:00+00:00             5     0.540067\n"
     ]
    }
   ],
   "source": [
    "def run_daily_inference():\n",
    "    date = fetch_latest_raw_data()\n",
    "\n",
    "    print(\"Date used one the fetch data raw\", date)\n",
    "    X = obtain_data_fv(date)\n",
    "\n",
    "    X_engi = util.geomagnetic_feature_engineering(X)\n",
    "    \n",
    "    X_engi = X_engi.sort_values(\"date\").tail(1).reset_index(drop=True)\n",
    "    \n",
    "    date = X_engi.loc[0, \"date\"]\n",
    "\n",
    "    X_engi.drop(columns=['date'], inplace=True)\n",
    "    \n",
    "    predictions = run_models(X_engi, date)\n",
    "\n",
    "    print(predictions)\n",
    "    #save_predictions(predictions)\n",
    "\n",
    "\n",
    "run_daily_inference()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
